{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvXlgmdfp8v8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This script builds a HuggingFace dataset from the combined dataset.\n",
        "\"\"\"\n",
        "\n",
        "import csv\n",
        "import json\n",
        "import random\n",
        "import unicodedata\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "def sanitize_row(row: Dict[str, str]) -> Dict[str, str]:\n",
        "    \"\"\"Sanitizes the data in a row to ensure it is valid UTF-8, normalized, and free of known ambiguous characters.\"\"\"\n",
        "    sanitized_row = {}\n",
        "    for key, value in row.items():\n",
        "        # Normalize to NFC form\n",
        "        normalized_value = unicodedata.normalize(\"NFC\", value)\n",
        "        # Replace common ambiguous characters\n",
        "        normalized_value = normalized_value.replace(\"“\", '\"').replace(\"”\", '\"')\n",
        "        normalized_value = normalized_value.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "        normalized_value = normalized_value.replace(\n",
        "            \"—\", \"-\"\n",
        "        )  # Replace em-dash with hyphen\n",
        "        # Encode to UTF-8 to ensure compatibility\n",
        "        sanitized_row[key] = normalized_value.encode(\"utf-8\", \"replace\").decode(\"utf-8\")\n",
        "    return sanitized_row\n",
        "\n",
        "\n",
        "def read_and_transform_csv(input_file_path: str, output_json_path: str):\n",
        "    data = []\n",
        "    with open(input_file_path, mode=\"r\", encoding=\"utf-8\") as file:\n",
        "        reader = csv.DictReader(file)\n",
        "        for row in reader:\n",
        "            sanitized_row = sanitize_row(row)\n",
        "            try:\n",
        "                # Parse the JSON string from the sanitized CSV to ensure it's valid and properly escaped\n",
        "                output_json = json.loads(sanitized_row[\"json_response\"])\n",
        "                # Re-serialize to JSON string to ensure proper formatting and escaping\n",
        "                output_json_string = json.dumps(output_json)\n",
        "            except json.JSONDecodeError:\n",
        "                # Handle cases where the JSON data is invalid\n",
        "                output_json_string = \"{}\"  # Use an empty JSON object as a fallback\n",
        "\n",
        "            # Create the conversation format for each entry\n",
        "            conversation = {\n",
        "                \"conversations\": [\n",
        "                    {\n",
        "                        \"from\": \"system\",\n",
        "\n",
        "                        \"value\": \"You are a smart assistant trained to detect buying intentions in a user's text. When given a user's input, you will respond in JSON format with three fields: \\\"buy_inten\\\", \\\"inten_level\\\", and \\\"cat\\\". \\\"buy_inten\\\" indicates whether there is a buying intention in the user's text. It should be 1 if there is a buying intention and 0 if there is not. \\\"inten_level\\\" represents the level of buying intention on a scale from 0 to 5, where 0 means no buying intention and 5 is the highest buying intention. \\\"cat\\\" specifies the category of the text, which could be any of the following: [\\\"Home & Kitchen\\\", \\\"Beauty & Personal Care\\\", \\\"Electronics\\\", \\\"Clothing, Shoes & Jewelry\\\", \\\"Toys & Games\\\", \\\"Health, Household & Baby Care\\\", \\\"Sports & Outdoors\\\", \\\"Pet Supplies\\\", \\\"Office Supplies\\\", \\\"Automotive\\\", \\\"General\\\"]. The category is selected as \\\"General\\\" when there is no exclusive category that can be found among others. For example, given the user's text: \\\"I'm looking for a new laptop,\\\" the JSON response should be: {\\\"buy_inten\\\": 1, \\\"inten_level\\\": 4, \\\"cat\\\": \\\"Electronics\\\"}. Ensure that your analysis is accurate and the JSON response strictly follows the specified format.\"\n",
        "                    },\n",
        "                    {\"from\": \"human\", \"value\": sanitized_row[\"text\"]},\n",
        "                    {\"from\": \"gpt\", \"value\": output_json_string},\n",
        "                ]\n",
        "            }\n",
        "            data.append(conversation)\n",
        "\n",
        "    # Randomize the order of data entries\n",
        "    random.shuffle(data)\n",
        "\n",
        "    with open(output_json_path, mode=\"w\", encoding=\"utf-8\") as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    input_csv_path = \"wop_json.csv\"\n",
        "    output_json_path = \"wop_aigot_hf_dataset.json\"\n",
        "    read_and_transform_csv(input_csv_path, output_json_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'wop_dataset.csv'  # Change this to the path of your local CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "# df['inten_level'] = (df['inten_level']/2).round()\n",
        "\n",
        "\n",
        "output_file_path = 'wop_dataset.csv'\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "# Convert the inten_level column to integer\n",
        "df['inten_level'] = df['inten_level'].astype(int)\n",
        "\n",
        "# Create the new column with JSON format\n",
        "df['json_response'] = df.apply(lambda row: json.dumps({\n",
        "    \"buy_inten\": row['buy_inten'],\n",
        "    \"inten_level\": row['inten_level'],\n",
        "    \"cat\": row['cat']\n",
        "}), axis=1)\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_file_path = 'wop_json.csv'  # Change this to your desired output path\n",
        "df.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Updated CSV file created successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sjzPnjDyiMh",
        "outputId": "1aeef0ba-700e-4ab8-9245-8d7c872b4e3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated CSV file created successfully.\n"
          ]
        }
      ]
    }
  ]
}